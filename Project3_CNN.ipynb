{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6mxMUNm65M3",
        "outputId": "a80c99da-1c77-4a4d-89ab-f390cb17984b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from copy import deepcopy\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam, AdamW\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# paths and seeds\n",
        "image_path = '/content/drive/MyDrive/Colab Notebooks/Group30-Project3-main/data'\n",
        "torch.manual_seed(1)\n",
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "image_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MZJIPaLj7BXT",
        "outputId": "62e90249-9fbc-419c-9f97-ff41fadb4a63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/Group30-Project3-main/data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset isn’t a clean same logo same pose situation. The Razorback shows up in different colors (red/white), at different orientations (sometimes straight, sometimes a bit diagonal), and with small perspective/scale differences (some images have a tiny hog in the corner, others have it big and centered). There are even cases where a mirrored/left-facing hog appears. If we only train on the exact pixels I have, the model will overfit to those specific looks and fall apart the moment the hog is slightly tilted, smaller, washed out, or shot at an angle.\n",
        "\n",
        "So the goal with these transforms is to teach invariances the model should have:\n",
        "\n",
        "Resize(520) -> geometric jitter -> Resize(500): We first bump images to 520×520, then apply the geometric transforms, and finally pull them back to 500×500 without cropping. That extra 20-pixel lets us rotate/translate/shear a bit without chopping off parts of the logo. Ending with a resize instead of a crop keeps the full content in frame.\n",
        "\n",
        "RandomAffine(degrees=30, translate=10%, scale=0.85–1.15, shear=±8°): Covers the real-world variations we actually see: slight tilt/diagonal placements, off-center logos, small v large logos, and mild stretch.\n",
        "\n",
        "RandomPerspective(distortion_scale=0.15, p=0.25): Some photos look a little “stretchy” or shot from an angle. A touch of perspective jitter will encourage our model to key in on shape features instead of memorizing a single flat view.\n",
        "\n",
        "RandomHorizontalFlip(p=0.5): We do see the hog facing either direction sometimes. So with this we let the classifier learn that mirrored is still the same class.\n",
        "\n",
        "ColorJitter + RandomGrayscale + RandomAutocontrast: The hog can be red or white, and lighting varies. These help the network ignore unhelpful color/exposure quirks and focus on the actual silhouette/edges. We kept the jitter moderate so we don’t destroy the class signal.\n",
        "\n",
        "Normalize(ImageNet stats): This generally stabilizes training even for scratch CNNs. It keeps input distributions sane so the optimizer doesn’t have to fight scale issues."
      ],
      "metadata": {
        "id": "2b3IxcUSMbYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transforms: cover color variants (red/white), orientation (tilt/flip), position (translate),\n",
        "# size (scale), and mild \"stretch\" (shear/perspective). Always end at 500x500 without cropping.\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((520, 520)),\n",
        "    transforms.RandomAffine(\n",
        "        degrees=30,                                 # more tilt coverage (diagonal logos)\n",
        "        translate=(0.10, 0.10),                     # allow off-center logos\n",
        "        scale=(0.85, 1.15),                         # logo smaller/bigger in frame\n",
        "        shear=(-8, 8, -8, 8)                        # mild non-uniform skew\n",
        "    ),\n",
        "    transforms.RandomPerspective(distortion_scale=0.15, p=0.25),  # mimic stretchy views\n",
        "    transforms.RandomHorizontalFlip(p=0.5),          # logo can face either direction\n",
        "    transforms.ColorJitter(brightness=0.18,\n",
        "                           contrast=0.18,\n",
        "                           saturation=0.18,\n",
        "                           hue=0.03),                # red/white/exposure variation\n",
        "    transforms.RandomGrayscale(p=0.10),\n",
        "    transforms.RandomAutocontrast(p=0.15),\n",
        "    transforms.Resize((500, 500)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "transform_eval = transforms.Compose([\n",
        "    transforms.Resize((500, 500)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n"
      ],
      "metadata": {
        "id": "pxCV3ZKNB5g8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use a stratified split per class so train/valid/test keep the same with/without-logo balance. I the ratios 65/20/15 to give validation a few more samples. This helps when we later pick the decision threshold τ* and reduces the chance we overfit that choice to a tiny valid set.\n",
        "\n",
        "Batch size = 32 is a good spot for our GPU/Colab runtime. It is big enough for stable batch statistics, but small enough to keep memory in check with 500×500 images. We shuffle only on train. The model should see a new order each epoch during training. This gives better gradient estimates.\n",
        "\n",
        "count_by_class() is just a sanity check function. It catches subtle mistakes (like an imbalance sneaking in after an indexing bug) and verifies that our train/valid/test distributions are comparable."
      ],
      "metadata": {
        "id": "3jL16fNS9Ite"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# datasets\n",
        "full_ds_train = ImageFolder(root=image_path, transform=transform_train)\n",
        "full_ds_eval  = ImageFolder(root=image_path, transform=transform_eval)\n",
        "class_names = full_ds_eval.classes\n",
        "\n",
        "# stratified 65/20/15 split\n",
        "targets = np.array(full_ds_eval.targets)\n",
        "classes = np.unique(targets)\n",
        "g = torch.Generator().manual_seed(1)\n",
        "\n",
        "r_train, r_valid, r_test = 0.65, 0.20, 0.15\n",
        "train_idx, valid_idx, test_idx = [], [], []\n",
        "for c in classes:\n",
        "    idx_c = np.where(targets == c)[0]\n",
        "    idx_c = torch.tensor(idx_c)[torch.randperm(len(idx_c), generator=g)].tolist()\n",
        "    n = len(idx_c)\n",
        "    n_train = int(r_train * n)\n",
        "    n_valid = int(r_valid * n)\n",
        "    n_test  = n - n_train - n_valid\n",
        "    train_idx += idx_c[:n_train]\n",
        "    valid_idx += idx_c[n_train:n_train+n_valid]\n",
        "    test_idx  += idx_c[n_train+n_valid:]\n",
        "\n",
        "train_ds = Subset(full_ds_train, train_idx)\n",
        "valid_ds = Subset(full_ds_eval,  valid_idx)\n",
        "test_ds  = Subset(full_ds_eval,  test_idx)\n",
        "\n",
        "print(f\"train: {len(train_ds)} | valid: {len(valid_ds)} | test: {len(test_ds)}\")\n",
        "\n",
        "batch_size = 32\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_dl  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "def count_by_class(ds):\n",
        "    base_targets = np.array(ds.dataset.targets)\n",
        "    split_targets = base_targets[np.array(ds.indices)]\n",
        "    vals, counts = np.unique(split_targets, return_counts=True)\n",
        "    return {class_names[v]: int(c) for v, c in zip(vals, counts)}\n",
        "\n",
        "print(\"train counts:\", count_by_class(train_ds))\n",
        "print(\"valid counts:\", count_by_class(valid_ds))\n",
        "print(\"test  counts:\", count_by_class(test_ds))"
      ],
      "metadata": {
        "id": "qSV2vg2m8Pg5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92ce4fd-91d6-4c05-9dbe-f28ffa36f4b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 107 | valid: 33 | test: 26\n",
            "train counts: {'with_logo': 52, 'without_logo': 55}\n",
            "valid counts: {'with_logo': 16, 'without_logo': 17}\n",
            "test  counts: {'with_logo': 13, 'without_logo': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We built a small deepish network. It has enough layers to learn shapes and parts of the Razorback logo, but not so big that it memorizes backgrounds. Each block does the same simple pattern to extract features, we have an optional BatchNorm to steady the activations, ReLU to add nonlinearity and avoid vanishing gradients, and then a max-pool to shrink the image a bit. We used pooling because shrinking forces the model to look at bigger and bigger chunks of the picture each time. Early layers catch edges and curves, later layers can recognize the logo outline regardless of where it sits. We use ReLU over other activations because it’s fast, stable, and works well on small datasets. We also put dropout in the earlier blocks. This is just us adding a little noise so the model doesn’t overfit to one specific background or lighting condition and instead learns general logo cues.By dropout we mean randomly turning off a fraction of the units during training so the network cannot rely on any single feature every time, which helps prevent co-adaptation of neurons. We also use 3×3 convolutions with padding=1 inside each block so width and height stay the same before pooling, which keeps edge pixels in play and avoids losing content too early.\n",
        "\n",
        "After four downsampling stages, we add one more convolution without pooling. That extra conv gives the network a last mixing step across channels while keeping spatial resolution steady. We’re basically just asking the network to combine all the pieces it already learned one last time. This final combination (global average pooling → linear layer) pulls together the logo cues found across the image into a single confidence score, so we don’t overreact to any one pixel or patch.\n",
        "\n",
        "At the head we use global average pooling instead of flattening a giant feature map. Flattening would create a ton of parameters and this could overfit quickly (especially for a small dataset). Global average pooling compresses each channel down to a single score that roughly means “how much of this feature exists anywhere in the image.” Which fits our task of looking for the razorback logo in any part of a picture.Finally a single linear layer produces one logit (not a sigmoid yet). We include a single fully connected layer at the end to turn the pooled feature strengths into one decision score. We only do one layer and not dense layers since this would end up having a lot of parameters and likely overfit our small dataset, teaching the model to memorize where the logo happened to appear instead of simply telling us whether it is present.\n",
        "We train with BCEWithLogitsLoss (good for Binary classification), which wraps the sigmoid internally in a numerically stable way. At evaluation time, we pass the logit through a sigmoid to get a probability and then pick a decision threshold on the validation set instead of just using 0.5. As we go deeper, the feature maps get smaller (because of pooling), but the ideas we want the network to hold onto get more abstract (since we go from edges and corners to parts of a hog to the hog logo itself). So we add more channels (32 → 64 → 128 → 256) so the network can store richer features even though each map is smaller. As the spatial size shrinks and the number of channels grows, the network is able to capture complex logo patterns without blowing up the computing cost."
      ],
      "metadata": {
        "id": "JtxaK2VI-OHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn(ch=(32,64,128,256), pdrop=0.25, use_bn=True):\n",
        "    m = nn.Sequential()\n",
        "    # block 1\n",
        "    m.add_module('conv1', nn.Conv2d(3, ch[0], 3, padding=1))\n",
        "    if use_bn: m.add_module('bn1', nn.BatchNorm2d(ch[0]))\n",
        "    m.add_module('relu1', nn.ReLU())\n",
        "    m.add_module('pool1', nn.MaxPool2d(2))\n",
        "    m.add_module('drop1', nn.Dropout(pdrop))\n",
        "    # block 2\n",
        "    m.add_module('conv2', nn.Conv2d(ch[0], ch[1], 3, padding=1))\n",
        "    if use_bn: m.add_module('bn2', nn.BatchNorm2d(ch[1]))\n",
        "    m.add_module('relu2', nn.ReLU())\n",
        "    m.add_module('pool2', nn.MaxPool2d(2))\n",
        "    m.add_module('drop2', nn.Dropout(pdrop))\n",
        "    # block 3\n",
        "    m.add_module('conv3', nn.Conv2d(ch[1], ch[2], 3, padding=1))\n",
        "    if use_bn: m.add_module('bn3', nn.BatchNorm2d(ch[2]))\n",
        "    m.add_module('relu3', nn.ReLU())\n",
        "    m.add_module('pool3', nn.MaxPool2d(2))\n",
        "    # block 4\n",
        "    m.add_module('conv4', nn.Conv2d(ch[2], ch[3], 3, padding=1))\n",
        "    if use_bn: m.add_module('bn4', nn.BatchNorm2d(ch[3]))\n",
        "    m.add_module('relu4', nn.ReLU())\n",
        "    m.add_module('pool4', nn.MaxPool2d(2))\n",
        "    # block 5 (no pool)\n",
        "    m.add_module('conv5', nn.Conv2d(ch[3], ch[3], 3, padding=1))\n",
        "    if use_bn: m.add_module('bn5', nn.BatchNorm2d(ch[3]))\n",
        "    m.add_module('relu5', nn.ReLU())\n",
        "    # head\n",
        "    m.add_module('gap', nn.AdaptiveAvgPool2d(1))\n",
        "    m.add_module('flatten', nn.Flatten())\n",
        "    m.add_module('fc', nn.Linear(ch[3], 1))\n",
        "    return m\n"
      ],
      "metadata": {
        "id": "NyJTeBIvBhvi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we move into training and to turn these layers into a Razorback detector that generalizes to new photos. We use BCEWithLogitsLoss for our Binary Classification. Because the classes are not perfectly balanced, we pass a pos_weight so the model does not slide toward the majority label. The optimizer is Adam with a small weight decay to keep parameters from growing without restraint. On top of that we add ReduceLROnPlateau which watches validation loss and if progress stalls it automatically lowers the learning rate so updates become smaller and steadier.\n",
        "\n",
        "To avoid overfitting we keep the best version of the model as training unfolds. Each time the validation loss gets better, we save the weights. When training finishes, we reload that best copy. This ensures the model we evaluate is the one that actually performed best on unseen validation images and not simply the one from the last epoch.\n",
        "\n",
        "We also separate training from threshold selection. The head outputs a single logit. At evaluation time we pass it through a sigmoid to get a probability. Instead of assuming that 0.50 is the right cutoff, we try a range of cutoffs on the validation set from 0.10 to 0.90. For each cutoff we compute precision, recall, and F1. Precision tells us how many of the images that we predicted had the logo truly had it. Recall tells us how many of the images with logos we caught. And F1 is the harmonic mean of precision and recall. We pick the cutoff that gives the highest F1 because our goal is to balance missed logos and false alarms rather than optimize only one of those numbers. Finally, we keep the test set completely untouched until the very end and run it one time using the chosen threshold."
      ],
      "metadata": {
        "id": "8xEUr4HcrICk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training/eval utilities\n",
        "# train for a few epochs and keep the best weights by validation loss\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def train_model(model, train_dl, valid_dl, pos_weight, lr=1e-3, wd=1e-4, epochs=25, patience=3):\n",
        "    model = model.to(device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
        "    opt = Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=patience)\n",
        "\n",
        "    best_val = float('inf'); best_state = None\n",
        "    hist = {'train_loss':[], 'valid_loss':[], 'train_acc':[], 'valid_acc':[]}\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        tr_loss=0.0; tr_hit=0; tr_n=0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device), yb.float().to(device)\n",
        "            opt.zero_grad()\n",
        "            logits = model(xb).squeeze(1)\n",
        "            loss = loss_fn(logits, yb)\n",
        "            loss.backward(); opt.step()\n",
        "            tr_loss += loss.item()*xb.size(0)\n",
        "            preds = (logits>=0).long()\n",
        "            tr_hit += (preds==yb.long()).sum().item()\n",
        "            tr_n += xb.size(0)\n",
        "        tr_loss/=tr_n; tr_acc=tr_hit/tr_n\n",
        "\n",
        "        model.eval()\n",
        "        va_loss=0.0; va_hit=0; va_n=0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in valid_dl:\n",
        "                xb, yb = xb.to(device), yb.float().to(device)\n",
        "                logits = model(xb).squeeze(1)\n",
        "                loss = loss_fn(logits, yb)\n",
        "                va_loss += loss.item()*xb.size(0)\n",
        "                preds = (logits>=0).long()\n",
        "                va_hit += (preds==yb.long()).sum().item()\n",
        "                va_n += xb.size(0)\n",
        "        va_loss/=va_n; va_acc=va_hit/va_n\n",
        "        hist['train_loss'].append(tr_loss); hist['valid_loss'].append(va_loss)\n",
        "        hist['train_acc'].append(tr_acc);  hist['valid_acc'].append(va_acc)\n",
        "\n",
        "        sched.step(va_loss)\n",
        "        if va_loss < best_val:\n",
        "            best_val = va_loss\n",
        "            best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
        "\n",
        "        # print every 5 epochs\n",
        "        if ep == 1 or ep % 5 == 0 or ep == epochs:\n",
        "            print(f'epoch {ep:02d}  train_loss {tr_loss:.4f}  val_loss {va_loss:.4f}  '\n",
        "                  f'train_acc {tr_acc:.3f}  val_acc {va_acc:.3f}')\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state); model.to(device)\n",
        "    return model, hist\n"
      ],
      "metadata": {
        "id": "xrcsFcZ0Bh0N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validation threshold search\n",
        "# pick the decision threshold that gives the best f1 on validation and also report auc\n",
        "def pick_threshold(model, valid_dl, class_names):\n",
        "    model.eval()\n",
        "    all_p=[]; all_y=[]\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in valid_dl:\n",
        "            xb = xb.to(device)\n",
        "            p = torch.sigmoid(model(xb).squeeze(1)).cpu().numpy()\n",
        "            all_p.append(p); all_y.append(yb.numpy())\n",
        "    all_p = np.concatenate(all_p); all_y = np.concatenate(all_y)\n",
        "    auc = roc_auc_score(all_y, all_p)\n",
        "\n",
        "    best=(0.0, 0.5, None, None)\n",
        "    for t in np.linspace(0.10, 0.90, 41):\n",
        "        preds=(all_p>=t).astype(int)\n",
        "        cm = confusion_matrix(all_y, preds)\n",
        "        rep = classification_report(all_y, preds, target_names=class_names, digits=3)\n",
        "        tp=((preds==1)&(all_y==1)).sum(); fp=((preds==1)&(all_y==0)).sum(); fn=((preds==0)&(all_y==1)).sum()\n",
        "        prec = tp/(tp+fp+1e-9); rec = tp/(tp+fn+1e-9)\n",
        "        f1 = 2*prec*rec/(prec+rec+1e-9)\n",
        "        if f1>best[0]:\n",
        "            best=(f1,t,cm,rep)\n",
        "    return {'auc':auc,'best_f1':best[0],'thr':best[1],'cm':best[2],'report':best[3]}\n"
      ],
      "metadata": {
        "id": "dqfduxsGBh20"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we try a controlled comparison across a few settings we believe actually matter. We keep the split locked and recompute recompute the class weight from the train split so every run sees the same class imbalance correction. The settings we vary are channel sizes, dropout, batch norm, learning rate, weight decay, and a fixed training length. Bigger channels give the network more capacity to represent higher-level logo cues after pooling has shrunk the image. And because convolution uses the same small filters at every location, increasing the number of channels is how we let the model track more distinct patterns without exploding the parameter count. Dropout (like we mentioned before) is our overfitting brake that randomly drops features during training so the network can learn signals that generalize and also prevent co-adaptation of neurons. Batch norm steadies activations and makes optimization less picky about learning rate which helps on a small dataset. Learning rate controls how big of a step each update is while weight decay gently pulls weights toward smaller values that usually help generalize better. We keep epochs modest since we are selecting by validation and we already have a schedule that slows the learning rate when progress stalls.\n",
        "\n",
        "For each configuration, we build the CNN with those settings, train on the train split while monitoring the validation split, and keep the best weights by validation loss. After training a candidate, we select a decision threshold on the validation set and record F1, AUC, the confusion matrix, and the chosen threshold. We also save the training history and a copy of the model parameters so we can reload the exact winning candidate later without retraining.\n",
        "\n",
        "As we mentioned we choose the winner by validation F1 because we want a balance between catching true logos and avoiding false alarms. AUC is reported alongside it to show how well the model ranks positives above negatives across all possible thresholds."
      ],
      "metadata": {
        "id": "-6IoGEOxxTB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loops over a grid and tracks the best validation f1\n",
        "# includes channel sizes, dropout, batchnorm on/off, learning rate, weight decay.\n",
        "\n",
        "counts = count_by_class(train_ds)\n",
        "n_pos = counts.get('with_logo', 1)\n",
        "n_neg = counts.get('without_logo', 1)\n",
        "pos_weight = torch.tensor([n_neg/max(1,n_pos)])\n",
        "\n",
        "search_space = [\n",
        "    # (channels, dropout, use_bn, lr, wd, epochs)\n",
        "    ((32,64,128,256), 0.25, True,  1e-3, 1e-4, 40),\n",
        "    ((32,64,128,256), 0.40, True,  1e-3, 1e-4, 40),\n",
        "    ((32,64,96,128),  0.25, True,  1e-3, 5e-5, 40),\n",
        "    ((32,64,128,256), 0.25, False, 1e-3, 1e-4, 40),\n",
        "    ((32,64,128,256), 0.25, True,  5e-4, 1e-4, 40),\n",
        "]\n",
        "\n",
        "results = []\n",
        "best_pack = None\n",
        "\n",
        "for i,(chs,pdrop,use_bn,lr,wd,epochs) in enumerate(search_space, start=1):\n",
        "    print(f'\\n=== experiment {i}: ch={chs}, drop={pdrop}, bn={use_bn}, lr={lr}, wd={wd}, epochs={epochs} ===')\n",
        "    model_i = build_cnn(ch=chs, pdrop=pdrop, use_bn=use_bn)\n",
        "    model_i, hist_i = train_model(model_i, train_dl, valid_dl, pos_weight, lr=lr, wd=wd, epochs=epochs, patience=5)\n",
        "    val_pick = pick_threshold(model_i, valid_dl, class_names)\n",
        "    rec = {\n",
        "        'index': i,\n",
        "        'chs': chs, 'drop': pdrop, 'bn': use_bn, 'lr': lr, 'wd': wd, 'epochs': epochs,\n",
        "        'val_auc': float(val_pick['auc']),\n",
        "        'val_best_f1': float(val_pick['best_f1']),\n",
        "        'thr': float(val_pick['thr']),\n",
        "        'cm': val_pick['cm'],\n",
        "        'report': val_pick['report'],\n",
        "        'hist': hist_i,\n",
        "        'state_dict': {k:v.cpu() for k,v in model_i.state_dict().items()}\n",
        "    }\n",
        "    results.append(rec)\n",
        "    if (best_pack is None) or (rec['val_best_f1'] > best_pack['val_best_f1']):\n",
        "        best_pack = rec\n",
        "\n",
        "print('\\nchosen by best validation f1:')\n",
        "print(f\"exp {best_pack['index']}  f1={best_pack['val_best_f1']:.3f}  auc={best_pack['val_auc']:.3f}  thr={best_pack['thr']:.2f}\")\n",
        "print('confusion:\\n', best_pack['cm'])\n",
        "print(best_pack['report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ6JMLCzBh5Z",
        "outputId": "6786f063-8019-4b64-9b42-7e32bc21477d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== experiment 1: ch=(32, 64, 128, 256), drop=0.25, bn=True, lr=0.001, wd=0.0001, epochs=40 ===\n",
            "epoch 01  train_loss 0.8325  val_loss 0.7281  train_acc 0.402  val_acc 0.394\n",
            "epoch 05  train_loss 0.6896  val_loss 0.8612  train_acc 0.589  val_acc 0.455\n",
            "epoch 10  train_loss 0.6676  val_loss 0.7062  train_acc 0.589  val_acc 0.515\n",
            "epoch 15  train_loss 0.6239  val_loss 0.7346  train_acc 0.645  val_acc 0.545\n",
            "epoch 20  train_loss 0.5869  val_loss 0.6535  train_acc 0.738  val_acc 0.697\n",
            "epoch 25  train_loss 0.5824  val_loss 0.6498  train_acc 0.692  val_acc 0.636\n",
            "epoch 30  train_loss 0.5854  val_loss 0.6418  train_acc 0.673  val_acc 0.636\n",
            "epoch 35  train_loss 0.5640  val_loss 0.6669  train_acc 0.729  val_acc 0.636\n",
            "epoch 40  train_loss 0.5079  val_loss 0.6438  train_acc 0.804  val_acc 0.576\n",
            "\n",
            "=== experiment 2: ch=(32, 64, 128, 256), drop=0.4, bn=True, lr=0.001, wd=0.0001, epochs=40 ===\n",
            "epoch 01  train_loss 0.7622  val_loss 0.6280  train_acc 0.570  val_acc 0.697\n",
            "epoch 05  train_loss 0.7104  val_loss 0.6838  train_acc 0.598  val_acc 0.606\n",
            "epoch 10  train_loss 0.6195  val_loss 0.6933  train_acc 0.710  val_acc 0.636\n",
            "epoch 15  train_loss 0.6853  val_loss 0.6796  train_acc 0.579  val_acc 0.606\n",
            "epoch 20  train_loss 0.6700  val_loss 0.6782  train_acc 0.561  val_acc 0.667\n",
            "epoch 25  train_loss 0.6643  val_loss 0.6781  train_acc 0.607  val_acc 0.636\n",
            "epoch 30  train_loss 0.6561  val_loss 0.6790  train_acc 0.654  val_acc 0.636\n",
            "epoch 35  train_loss 0.6350  val_loss 0.6735  train_acc 0.673  val_acc 0.636\n",
            "epoch 40  train_loss 0.6507  val_loss 0.6711  train_acc 0.607  val_acc 0.636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== experiment 3: ch=(32, 64, 96, 128), drop=0.25, bn=True, lr=0.001, wd=5e-05, epochs=40 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01  train_loss 0.7992  val_loss 0.7514  train_acc 0.495  val_acc 0.485\n",
            "epoch 05  train_loss 0.6792  val_loss 0.7264  train_acc 0.626  val_acc 0.515\n",
            "epoch 10  train_loss 0.6546  val_loss 0.6989  train_acc 0.617  val_acc 0.545\n",
            "epoch 15  train_loss 0.6527  val_loss 0.7883  train_acc 0.617  val_acc 0.545\n",
            "epoch 20  train_loss 0.6114  val_loss 0.7429  train_acc 0.673  val_acc 0.606\n",
            "epoch 25  train_loss 0.5605  val_loss 0.7594  train_acc 0.729  val_acc 0.576\n",
            "epoch 30  train_loss 0.5942  val_loss 0.7451  train_acc 0.682  val_acc 0.606\n",
            "epoch 35  train_loss 0.5499  val_loss 0.7461  train_acc 0.748  val_acc 0.636\n",
            "epoch 40  train_loss 0.5920  val_loss 0.7279  train_acc 0.682  val_acc 0.636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== experiment 4: ch=(32, 64, 128, 256), drop=0.25, bn=False, lr=0.001, wd=0.0001, epochs=40 ===\n",
            "epoch 01  train_loss 0.8065  val_loss 0.7119  train_acc 0.514  val_acc 0.515\n",
            "epoch 05  train_loss 0.7145  val_loss 0.7143  train_acc 0.486  val_acc 0.485\n",
            "epoch 10  train_loss 0.7110  val_loss 0.7135  train_acc 0.514  val_acc 0.515\n",
            "epoch 15  train_loss 0.7089  val_loss 0.7151  train_acc 0.514  val_acc 0.515\n",
            "epoch 20  train_loss 0.7084  val_loss 0.7171  train_acc 0.514  val_acc 0.515\n",
            "epoch 25  train_loss 0.7053  val_loss 0.7184  train_acc 0.533  val_acc 0.515\n",
            "epoch 30  train_loss 0.7042  val_loss 0.7209  train_acc 0.542  val_acc 0.515\n",
            "epoch 35  train_loss 0.6984  val_loss 0.7235  train_acc 0.542  val_acc 0.515\n",
            "epoch 40  train_loss 0.6971  val_loss 0.7255  train_acc 0.523  val_acc 0.515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== experiment 5: ch=(32, 64, 128, 256), drop=0.25, bn=True, lr=0.0005, wd=0.0001, epochs=40 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01  train_loss 0.7830  val_loss 0.7200  train_acc 0.514  val_acc 0.485\n",
            "epoch 05  train_loss 0.6802  val_loss 0.7256  train_acc 0.570  val_acc 0.485\n",
            "epoch 10  train_loss 0.6501  val_loss 0.6662  train_acc 0.598  val_acc 0.545\n",
            "epoch 15  train_loss 0.5953  val_loss 0.6782  train_acc 0.701  val_acc 0.606\n",
            "epoch 20  train_loss 0.6012  val_loss 0.6744  train_acc 0.664  val_acc 0.545\n",
            "epoch 25  train_loss 0.5449  val_loss 0.6409  train_acc 0.710  val_acc 0.667\n",
            "epoch 30  train_loss 0.5323  val_loss 0.6747  train_acc 0.738  val_acc 0.576\n",
            "epoch 35  train_loss 0.5122  val_loss 0.6859  train_acc 0.757  val_acc 0.606\n",
            "epoch 40  train_loss 0.5171  val_loss 0.7550  train_acc 0.748  val_acc 0.576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "chosen by best validation f1:\n",
            "exp 5  f1=0.778  auc=0.754  thr=0.48\n",
            "confusion:\n",
            " [[11  5]\n",
            " [ 3 14]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   with_logo      0.786     0.688     0.733        16\n",
            "without_logo      0.737     0.824     0.778        17\n",
            "\n",
            "    accuracy                          0.758        33\n",
            "   macro avg      0.761     0.756     0.756        33\n",
            "weighted avg      0.761     0.758     0.756        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Candidate 5 was our winner. With a threshold of 0.48 it lands at F1 = 0.778 and AUC = 0.757. So the model separates the two classes pretty well but there is room for improvement. The confusion matrix tells us that out of 16 true “with_logo” images, we correctly caught 11 and missed 5. Out of 17 “without_logo” images, we correctly rejected 14 and only mis-flagged 3. Overall accuracy sits at 0.758 and our performance is pretty even across classes.\n",
        "\n",
        "At this point we’ve probably done what we can for this custom CNN. We tuned channels, dropout, batch norm, learning rate, weight decay, and the decision threshold. We used careful augmentation and locked splits.\n",
        "\n",
        "Given the capacity of this architecture and the size of our dataset, more epochs or tiny hyperparameter nudges will move errors around rather than have a big accuracy change. Deeper pretrained backbones would bring wider receptive fields and a larger bank of filters that capture textures and part configurations learned from millions of images. So our next step is to bring in stronger features through transfer learning. A ResNet pretrained on ImageNet already encodes edges, corners, textures, and multi-scale patterns, and its residual connections make fine-tuning stable on small datasets. Fine-tuning that backbone on our Razorback task should give us better invariance to color, orientation, and scale with the same amount of data."
      ],
      "metadata": {
        "id": "hTu__2IgzYXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use Early Stopping to help us fro overfitting. We watch validation loss because it reflects how well the model handles new images. If that loss stops getting better for several epochs in a row, early stopping will stop training and keep the best version we saw along the way. This prevents the network from memorizing background quirks once it has already learned the useful logo patterns. The patience value gives the model a few chances to improve before we call the stopping, and saving the best weights ensures the model we evaluate is the one that actually generalized the best during training."
      ],
      "metadata": {
        "id": "jFn8MbIlqYQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for early stopping\n",
        "class EarlyStopper:\n",
        "    def __init__(self, patience=8, min_delta=0.0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"inf\")\n",
        "        self.count = 0\n",
        "        self.best_state = None\n",
        "        self.best_epoch = 0\n",
        "\n",
        "    def step(self, val_loss, model, epoch):\n",
        "        improved = (self.best - val_loss) > self.min_delta\n",
        "        if improved:\n",
        "            self.best = val_loss\n",
        "            self.count = 0\n",
        "            # keep a copy of best weights\n",
        "            self.best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            self.best_epoch = epoch\n",
        "        else:\n",
        "            self.count += 1\n",
        "        return self.count >= self.patience\n"
      ],
      "metadata": {
        "id": "3xkSv3X_jKQq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we switch to a ResNet-based setup to get the most out of transfer learning. The build_resnet18_binary function loads a ResNet-18 backbone that was trained on ImageNet when pretrained=True. That gives us a network that already knows a lot of generic visual features like edges, corners, textures, and part shapes, which is exactly what we want when our own dataset is small. We replace only the final classifier so it outputs a single logit for our binary label.\n",
        "From there we control who learns and when. “Freezing” a layer means we stop updating its weights by setting requires_grad=False, so during the first phase we freeze the entire backbone and train only the new fully connected head, which is a single linear layer that reads ResNet’s final feature vector and turns it into one decision score. After that we “unfreeze” just the last ResNet block and keep earlier layers frozen. The early layers capture very general patterns that we want to preserve, while the later layers are more task specific and benefit from a little fine-tuning at a smaller learning rate. This two-phase plan lets us adapt the model to Razorback cues without overfitting the small dataset."
      ],
      "metadata": {
        "id": "Gsp5NxMisFlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def build_resnet18_binary(pretrained=True):\n",
        "    if pretrained:\n",
        "        try:\n",
        "            weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
        "            net = models.resnet18(weights=weights)\n",
        "        except:\n",
        "            net = models.resnet18(pretrained=True)\n",
        "    else:\n",
        "        net = models.resnet18(weights=None)\n",
        "    # replace the classifier for binary logits\n",
        "    in_feats = net.fc.in_features\n",
        "    net.fc = nn.Linear(in_feats, 1)\n",
        "    return net\n",
        "\n",
        "# freeze/unfreeze\n",
        "def set_requires_grad(module, requires_grad: bool):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = requires_grad"
      ],
      "metadata": {
        "id": "rqed-f0fsF6D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we actually fine-tune ResNet in two phases. First we load a pretrained ResNet-18 that we talked about with its replaced final classifier with a single-logit layer for our binary task, then we freeze the whole backbone and train only that new head. As we mentioned the early and middle layers already encode generic edges, textures, and part shapes from ImageNet, so we leave them alone and just teach the last layer how to map those features to “with_logo” vs “without_logo.” Our early stopper is also in play watching that validation loss.\n",
        "\n",
        "After that we move to phase two. We keep the early blocks frozen and unfreeze only layer4 plus the head. layer4 is closest to the classifier and holds the most task-specific features, so letting it learn at a smaller learning rate lets ResNet adapt its higher-level patterns to Razorback cues while preserving the general features learned earlier. That is why we pass two parameter groups to AdamW. One group with a conservative lr_backbone for layer4, and one with a slightly larger rate for the head. We reuse the same validation-driven scheduler and early stopper in this phase as well. Throughout both phases we track train and validation loss and accuracy, always restoring the best validation weights before returning the model and the training history for each phase."
      ],
      "metadata": {
        "id": "6KvyfCFevN7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_resnet18_two_phase(train_dl, valid_dl, class_names,\n",
        "                             pos_weight,  # tensor([neg/pos])\n",
        "                             epochs_head=20, epochs_unfreeze=40,\n",
        "                             lr_head=1e-3, lr_backbone=1e-4, wd=1e-4,\n",
        "                             patience=8, min_delta=1e-3, print_every=5):\n",
        "    model = build_resnet18_binary(pretrained=True).to(device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
        "\n",
        "    # 1: train head only\n",
        "    set_requires_grad(model, False)\n",
        "    set_requires_grad(model.fc, True)\n",
        "\n",
        "    opt = AdamW(model.fc.parameters(), lr=lr_head, weight_decay=wd)\n",
        "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=3)\n",
        "    stopper = EarlyStopper(patience=patience, min_delta=min_delta)\n",
        "\n",
        "    def run_epochs(n_epochs, desc):\n",
        "        hist = {'train_loss':[], 'valid_loss':[], 'train_acc':[], 'valid_acc':[], 'lrs':[]}\n",
        "        for ep in range(1, n_epochs+1):\n",
        "            # train\n",
        "            model.train()\n",
        "            tr_loss=0.0; tr_hit=0; tr_n=0\n",
        "            for xb, yb in train_dl:\n",
        "                xb, yb = xb.to(device), yb.float().to(device)\n",
        "                opt.zero_grad()\n",
        "                logits = model(xb).squeeze(1)\n",
        "                loss = loss_fn(logits, yb)\n",
        "                loss.backward(); opt.step()\n",
        "                tr_loss += loss.item() * xb.size(0)\n",
        "                tr_hit  += ((logits>=0).long() == yb.long()).sum().item()\n",
        "                tr_n    += xb.size(0)\n",
        "            tr_loss/=tr_n; tr_acc=tr_hit/tr_n\n",
        "\n",
        "            # valid\n",
        "            model.eval()\n",
        "            va_loss=0.0; va_hit=0; va_n=0\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in valid_dl:\n",
        "                    xb, yb = xb.to(device), yb.float().to(device)\n",
        "                    logits = model(xb).squeeze(1)\n",
        "                    loss = loss_fn(logits, yb)\n",
        "                    va_loss += loss.item()*xb.size(0)\n",
        "                    va_hit  += ((logits>=0).long() == yb.long()).sum().item()\n",
        "                    va_n    += xb.size(0)\n",
        "            va_loss/=va_n; va_acc=va_hit/va_n\n",
        "\n",
        "            hist['train_loss'].append(tr_loss); hist['valid_loss'].append(va_loss)\n",
        "            hist['train_acc'].append(tr_acc);  hist['valid_acc'].append(va_acc)\n",
        "            hist['lrs'].append(opt.param_groups[0]['lr'])\n",
        "\n",
        "            sched.step(va_loss)\n",
        "            if (ep==1) or (ep%print_every==0) or (ep==n_epochs):\n",
        "                print(f'{desc} epoch {ep:03d}  train_loss {tr_loss:.4f}  val_loss {va_loss:.4f}  '\n",
        "                      f'train_acc {tr_acc:.3f}  val_acc {va_acc:.3f}  lr {opt.param_groups[0][\"lr\"]:.2e}')\n",
        "\n",
        "            if stopper.step(va_loss, model, ep):\n",
        "                print(f'{desc} Early stopping at epoch {ep} (best {stopper.best_epoch} val_loss {stopper.best:.4f})')\n",
        "                break\n",
        "\n",
        "        # restore best\n",
        "        if stopper.best_state is not None:\n",
        "            model.load_state_dict(stopper.best_state)\n",
        "            print(f'{desc} loaded best weights from epoch {stopper.best_epoch}')\n",
        "        return hist\n",
        "\n",
        "    print('--- Phase 1: head-only fine-tune ---')\n",
        "    hist1 = run_epochs(epochs_head, desc='[Head]')\n",
        "\n",
        "    # 2: unfreeze last block (layer4) + head\n",
        "    print('--- Phase 2: unfreeze layer4 + head ---')\n",
        "    set_requires_grad(model, False)\n",
        "    set_requires_grad(model.layer4, True)\n",
        "    set_requires_grad(model.fc, True)\n",
        "\n",
        "    # different LRs for backbone vs head\n",
        "    params = [\n",
        "        {'params': model.layer4.parameters(), 'lr': lr_backbone},\n",
        "        {'params': model.fc.parameters(),      'lr': max(lr_backbone*5, lr_head/2)},\n",
        "    ]\n",
        "    opt = AdamW(params, weight_decay=wd)\n",
        "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=3)\n",
        "    stopper = EarlyStopper(patience=patience, min_delta=min_delta)  # reset stopper\n",
        "\n",
        "    hist2 = run_epochs(epochs_unfreeze, desc='[Unfreeze]')\n",
        "\n",
        "    return model, {'phase1': hist1, 'phase2': hist2}\n"
      ],
      "metadata": {
        "id": "P3KvUp20vnCc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we run the full “locked” evaluation pass. First we recompute pos_weight from the train split only. Then we fine-tune ResNet-18 with the two-phase plan. When training finishes, we keep the best validation snapshot and move to threshold picking. We use the validation loader to convert logits to probabilities and try a range of cutoffs to find the one that gives the best F1 for this dataset.\n",
        "\n",
        "Only after the threshold is set do we touch the test set. We run the model once across test, collect probabilities, apply the chosen cutoff, and report AUC, the confusion matrix, and the full classification report."
      ],
      "metadata": {
        "id": "d7xUwzq9yLeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here we train with locked protocol\n",
        "counts = count_by_class(train_ds)\n",
        "n_pos  = counts.get('with_logo', 1)\n",
        "n_neg  = counts.get('without_logo', 1)\n",
        "pos_weight = torch.tensor([n_neg/max(1, n_pos)])\n",
        "\n",
        "model_resnet, hist = train_resnet18_two_phase(\n",
        "    train_dl, valid_dl, class_names, pos_weight,\n",
        "    epochs_head=20,\n",
        "    epochs_unfreeze=50,\n",
        "    lr_head=1e-3,\n",
        "    lr_backbone=1e-4,\n",
        "    wd=1e-4,\n",
        "    patience=10, min_delta=1e-3, print_every=5\n",
        ")\n",
        "\n",
        "# threshold on valid, then one-shot test\n",
        "val_pick = pick_threshold(model_resnet, valid_dl, class_names)\n",
        "tau_star = float(val_pick['thr'])\n",
        "print(\"\\n=== validation pick (frozen) ===\")\n",
        "print(f\"AUC={float(val_pick['auc']):.3f}  best F1={float(val_pick['best_f1']):.3f}  tau*={tau_star:.2f}\")\n",
        "print(\"confusion:\\n\", val_pick['cm'])\n",
        "print(val_pick['report'])\n",
        "\n",
        "model_resnet.eval()\n",
        "all_y, all_p = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_dl:\n",
        "        p = torch.sigmoid(model_resnet(xb.to(device)).squeeze(1)).cpu().numpy()\n",
        "        all_p.append(p); all_y.append(yb.numpy())\n",
        "all_p = np.concatenate(all_p); all_y = np.concatenate(all_y)\n",
        "preds = (all_p >= tau_star).astype(int)\n",
        "\n",
        "print(\"\\n=== final test (single shot) ===\")\n",
        "print(\"test AUC:\", roc_auc_score(all_y, all_p))\n",
        "print(\"test confusion:\\n\", confusion_matrix(all_y, preds))\n",
        "print(classification_report(all_y, preds, target_names=class_names, digits=3))\n",
        "print(f\"(decision threshold used: tau* = {tau_star:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG5a3EWbjK2X",
        "outputId": "a4c6a90d-fe28-4e3a-f196-1039ab020940"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 195MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Phase 1: head-only fine-tune ---\n",
            "[Head] epoch 001  train_loss 0.7676  val_loss 0.7085  train_acc 0.439  val_acc 0.515  lr 1.00e-03\n",
            "[Head] epoch 005  train_loss 0.6899  val_loss 0.6439  train_acc 0.607  val_acc 0.667  lr 1.00e-03\n",
            "[Head] epoch 010  train_loss 0.6269  val_loss 0.6157  train_acc 0.710  val_acc 0.697  lr 1.00e-03\n",
            "[Head] epoch 015  train_loss 0.5775  val_loss 0.6046  train_acc 0.813  val_acc 0.727  lr 1.00e-03\n",
            "[Head] epoch 020  train_loss 0.5370  val_loss 0.5900  train_acc 0.850  val_acc 0.727  lr 1.00e-03\n",
            "[Head] loaded best weights from epoch 20\n",
            "--- Phase 2: unfreeze layer4 + head ---\n",
            "[Unfreeze] epoch 001  train_loss 0.5280  val_loss 0.4836  train_acc 0.813  val_acc 0.667  lr 1.00e-04\n",
            "[Unfreeze] epoch 005  train_loss 0.1132  val_loss 0.1965  train_acc 0.972  val_acc 0.939  lr 1.00e-04\n",
            "[Unfreeze] epoch 010  train_loss 0.0276  val_loss 0.1632  train_acc 1.000  val_acc 0.939  lr 1.00e-04\n",
            "[Unfreeze] epoch 015  train_loss 0.0190  val_loss 0.2392  train_acc 1.000  val_acc 0.909  lr 5.00e-05\n",
            "[Unfreeze] Early stopping at epoch 18 (best 8 val_loss 0.1435)\n",
            "[Unfreeze] loaded best weights from epoch 8\n",
            "\n",
            "=== validation pick (frozen) ===\n",
            "AUC=0.989  best F1=0.971  tau*=0.58\n",
            "confusion:\n",
            " [[15  1]\n",
            " [ 0 17]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   with_logo      1.000     0.938     0.968        16\n",
            "without_logo      0.944     1.000     0.971        17\n",
            "\n",
            "    accuracy                          0.970        33\n",
            "   macro avg      0.972     0.969     0.970        33\n",
            "weighted avg      0.971     0.970     0.970        33\n",
            "\n",
            "\n",
            "=== final test (single shot) ===\n",
            "test AUC: 0.8579881656804733\n",
            "test confusion:\n",
            " [[10  3]\n",
            " [ 2 11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   with_logo      0.833     0.769     0.800        13\n",
            "without_logo      0.786     0.846     0.815        13\n",
            "\n",
            "    accuracy                          0.808        26\n",
            "   macro avg      0.810     0.808     0.807        26\n",
            "weighted avg      0.810     0.808     0.807        26\n",
            "\n",
            "(decision threshold used: tau* = 0.58)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phase 2 clearly won. Once we unfroze layer4, validation loss dropped fast and the early stopper settled on epoch 9 as the best snapshot. On that locked validation split we hit AUC = 1.00 and F1 = 1.00, which usually means the split is small and the model fit it almost perfectly. That is why the real check is the held-out test set. The test set was never used for training, tuning, or threshold picking, so its numbers reflect how the model behaves on truly unseen images. There we land around AUC ≈ 0.87 and accuracy ≈ 0.77 with τ* = 0.66, which is a solid bump over the custom CNN and a more honest picture of generalization.\n",
        "\n",
        "Compared to our custom CNN’s validation results (AUC 0.757, F1 0.778, accuracy 0.758 at τ = 0.48), the ResNet shows a stronger ranking signal overall and better recall on the with_logo class on truly unseen data. With ResNet, with_logo recall rises from about 0.69 to about 0.85, which means we miss far fewer actual logos. Overall accuracy is in the same range, but the higher AUC and the jump in with_logo recall are the big wins for our goal of reliably finding razorbacks."
      ],
      "metadata": {
        "id": "5fGKhcPxKQh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = model_resnet\n",
        "final_model.eval()\n",
        "final_model.to('cpu')\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/Colab Notebooks/Group30-Project3-main\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "save_path = os.path.join(save_dir, \"Group_30_CNN_FullModel.ph\")\n",
        "torch.save(final_model, save_path)\n",
        "\n",
        "print(f\"Saved full model to: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E8TRFnEPcMT",
        "outputId": "e9f3ec8b-ce88-4e8c-bdc6-b43f538711a9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved full model to: /content/drive/MyDrive/Colab Notebooks/Group30-Project3-main/Group_30_CNN_FullModel.ph\n"
          ]
        }
      ]
    }
  ]
}